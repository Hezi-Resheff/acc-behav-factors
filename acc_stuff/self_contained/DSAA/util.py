"""
...

"""
import numpy as np
import scipy.stats as stats
import pandas as pd
from sklearn.metrics import zero_one_loss, log_loss



class cmp:
    CMP_MAX = 0
    CMP_LOG = 1
    CMP_SETS = 2

def compare_partitions_hard(original_partition, new_partition, method):
    hard_new_partition = np.zeros_like(new_partition)
    hard_new_partition[range(new_partition.shape[0]), new_partition.argmax(axis=1)] = 1 
    return compare_partitions(original_partition, new_partition, method)

def compare_partitions(original_partiton, new_partition, method):
    """
    Used to compare the supervised partition of the ACC data to the partition 
    generated by one of the clustering methods. 
    """
    
    if method == cmp.CMP_MAX:
        """
        The new partiton <- argmax(new partiton values), and then assign each of the new partitions the 
        old partition that is the most frequent in it (largest overlap). Finally use a 0-1 loss. 
        """
        new_as_old = np.zeros_like(original_partiton)
        new_amax = new_partition.argmax(axis=1)
        for prt in np.unique(new_amax):
            map = new_amax == prt 
            old_partition_val = pd.Series(new_partition[:, prt]).groupby(original_partiton).mean().values.argmax()
            new_as_old[map] = old_partition_val
        return zero_one_loss(original_partiton, new_as_old)

    elif method == cmp.CMP_LOG:
        """
        Map old->new partitions like above, but then assign each sapmle a distribution on old partitons and use 
        a log loss
        """
        old_prt_vals = np.unique(original_partiton)
        new_as_old = np.zeros((len(original_partiton), len(old_prt_vals)))
        new_amax = new_partition.argmax(axis=1)
        for prt in range(new_partition.shape[1]):
            map = new_amax == prt 
            if not np.any(map): continue 
            old_partition_val = pd.Series(new_partition[:, prt]).groupby(original_partiton).mean().values.argmax()
            new_as_old[:, old_partition_val] += new_partition[:, prt]
        return log_loss(original_partiton, new_as_old, eps=1e-10)

    elif method == cmp.CMP_SETS:
        # The score for a cluster mapping is the |intersection| / |union| of the two partitions.
        # TODO: compute
        return 0
    else:
        raise TypeError("Compare method not implemented:  %s" % method)




def tests(compare_method):

    print("\n", "Using method: ", compare_method, "\n", "="*80)

    # 1) test compare_partitions with random data 
    k = 5
    k1 = 20
    N = 1000000
    orig_part = np.random.randint(0, k, N)
    new_part = np.random.rand(N, k1)
    
    new_old = np.zeros_like(new_part)
    new_old[range(N), orig_part] = 1
    
    score_same = compare_method(orig_part, new_old, cmp.CMP_MAX)
    score_max = compare_method(orig_part, new_part, cmp.CMP_MAX)
    print("Max partition score for one-hot of same data (0 expected): %f" % score_same)
    print("Max partition score for random data (~%.3f expected): %f" %(1- 1.0/k, score_max) )

    score_same_log = compare_method(orig_part, new_old, cmp.CMP_LOG)
    score_log = compare_method(orig_part, new_part, cmp.CMP_LOG)
    print("Max partition log score for one-hot of same data (0 expected): %f" % score_same_log)
    print("Max partition log score for random data (~%.3f expected): %f" %(-np.log(1.0/k), score_log) )

if __name__ == "__main__":
    tests(compare_method=compare_partitions)
    tests(compare_method=compare_partitions_hard)


