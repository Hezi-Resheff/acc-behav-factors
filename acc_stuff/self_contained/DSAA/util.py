"""
...

"""
import numpy as np
import scipy.stats as stats
import pandas as pd
from sklearn.cross_validation import train_test_split
from sklearn.metrics import zero_one_loss, log_loss
from sklearn.preprocessing import StandardScaler


class cmp:
    CMP_MAX = 0
    CMP_LOG = 1
    CMP_LOG_2 = 2
    CMP_SETS = 3

def one_hot(partition):
    """
    Transform a hard-assignment partition vector [1,2,2,3...] into a matrix with 1-indicators for the 
    partition [[0,1,0,0], [0,0,1,0], [0,0,1,0], [0,0,0,1]...]
    """
    N = len(partition)
    k = len(np.unique(partition))
    expanded = np.zeros((N, k))
    expanded[range(N), partition] = 1
    return expanded

def compare_partitions_hard(original_partition, new_partition, method):
    hard_new_partition = np.zeros_like(new_partition)
    hard_new_partition[range(new_partition.shape[0]), new_partition.argmax(axis=1)] = 1 
    return compare_partitions(original_partition, hard_new_partition, method)

def compare_partitions(original_partiton, new_partition, method):
    """
    Used to compare the supervised partition of the ACC data to the partition 
    generated by one of the clustering methods. 
    """

    # First we split everything into train/test
    N = len(original_partiton)
    train_ix, test_ix = train_test_split(range(N), train_size=.5)

    if method == cmp.CMP_MAX:
        """
        The new partiton <- argmax(new partiton values), and then assign each of the new partitions the 
        old partition that is the most frequent in it (largest overlap). Finally use a 0-1 loss. 
        """
        new_as_old = np.zeros_like(original_partiton)
        new_amax = new_partition.argmax(axis=1)
        for prt in np.unique(new_amax):
            map = new_amax == prt 
            old_partition_val = pd.Series(new_partition[train_ix, prt]).groupby(original_partiton[train_ix]).mean().values.argmax()
            new_as_old[map] = old_partition_val
        return zero_one_loss(original_partiton[test_ix], new_as_old[test_ix])

    elif method == cmp.CMP_LOG:
        """
        Map old->new partitions like above, and use a log loss
        """
        old_prt_vals = np.unique(original_partiton)
        new_as_old = np.zeros((len(original_partiton), len(old_prt_vals)))
        new_amax = new_partition.argmax(axis=1)
        for prt in range(new_partition.shape[1]):
            map = new_amax == prt 
            if not np.any(map):
                continue
            old_partition_val = pd.Series(new_partition[train_ix, prt]).groupby(original_partiton[train_ix]).mean().values.argmax()
            new_as_old[:, old_partition_val] += new_partition[:, prt]
        return log_loss(original_partiton[test_ix], new_as_old[test_ix], eps=1e-10)


    elif method == cmp.CMP_SETS:
        # The score for a cluster mapping is the |intersection| / |union| of the two partitions.
        # TODO: compute
        return 0
    else:
        raise TypeError("Compare method not implemented:  %s" % method)


def return_partitions(original_partiton, new_partition):
    # First we split everything into train/test
    N = len(original_partiton)
    train_ix, test_ix = train_test_split(range(N), train_size=.5)

    old_prt_vals = np.unique(original_partiton)
    new_as_old = np.zeros((len(original_partiton), len(old_prt_vals)))
    new_amax = new_partition.argmax(axis=1)
    for prt in range(new_partition.shape[1]):
        map = new_amax == prt
        if not np.any(map):
            continue
        old_partition_val = pd.Series(new_partition[train_ix, prt]).groupby(original_partiton[train_ix]).mean().values.argmax()
        new_as_old[:, old_partition_val] += new_partition[:, prt]

    return pd.DataFrame(new_as_old[test_ix], index=original_partiton[test_ix])


def tests(compare_method):

    print("\n", "Using method: ", compare_method, "\n", "="*80)

    # 1) test compare_partitions with random data 
    k = 5
    k1 = 20
    N = 1000000
    orig_part = np.random.randint(0, k, N)
    new_part = np.random.rand(N, k1)
    
    new_old = np.zeros_like(new_part)
    new_old[range(N), orig_part] = 1
    
    score_same = compare_method(orig_part, new_old, cmp.CMP_MAX)
    score_max = compare_method(orig_part, new_part, cmp.CMP_MAX)
    print("Max partition score for one-hot of same data (0 expected): %f" % score_same)
    print("Max partition score for random data (~%.3f expected): %f" %(1- 1.0/k, score_max) )

    score_same_log = compare_method(orig_part, new_old, cmp.CMP_LOG)
    score_log = compare_method(orig_part, new_part, cmp.CMP_LOG)
    print("Max partition log score for one-hot of same data (0 expected): %f" % score_same_log)
    print("Max partition log score for random data (~%.3f expected): %f" %(-np.log(1.0/k), score_log) )

if __name__ == "__main__":
    tests(compare_method=compare_partitions)
    tests(compare_method=compare_partitions_hard)


